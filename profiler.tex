\section{Profiling}
	\begin{itemize}
		\item Question: different data structures have different complexities. Adding something
			might be cheap on one, but extensive on another that is faster on removing them. But
			how can we compare them based on the accesses used?
		\item Idea: count each call to the data structures, compute the complexities at the
			end and give recommendations
		\item Achieved through AspectJ which can be used to add functionalities to existing code
			(see section \ref{sec:aspectj}). This enables us to keep nearly all profiler
			functionality seperated from the other code: the aspects to enable counting reside in
			\texttt{ProfilerAspects.aj}, the counterpart to count the accesses reside in
			the class \texttt{Profiler}
		\item On runtime, the profiler counts calls based on the performed action (add, remove,
			contains) and callee signature (metric name, update type,\ldots), such that we can
			determine the complexities for different use cases with one execution
		\item Combined complexities are computed based on the complexities for each action on
			each data structure, which are stored within each data structure class
		\item Access counters are written to the file \texttt{\_\_\_aggregated.\allowbreak
			profiler.\allowbreak values} with a list of distinguishable access types, summarized
			for each callee, and a recommendation for optimized complexities. As the computation of
			recommendations is time consuming, this is not done for each callee, but only for
			aggregations.
		\item Access counters are written alongside the other data: metric access counters to
			the metric's folder in the file \texttt{\_\_\_metric.\allowbreak
			profiler.\allowbreak values}, counters for the graph generation
			(\texttt{\_\_\_graphGeneration.\allowbreak profiler.\allowbreak values}), the batch
			generation (\texttt{\_\_\_batchGeneration.\allowbreak profiler.\allowbreak values}) and the batch
			applications (\texttt{\_\_\_updates.\allowbreak profiler.\allowbreak values}) in seperate files per
			batch and aggregated per run and series.
		\item Example output (shortened, full file at \ref{sec:exampleOutput}):
			
		\begin{verbatim}
			DegreeDistributionU.AddNodeGlobal=0
			DegreeDistributionU.AddNodeLocal=0
			[...]
			DegreeDistributionU.SizeEdgeLocal=96000
			DegreeDistributionU.RandomNodeGlobal=0
			DegreeDistributionU.RandomEdgeGlobal=0
			[...]
			#  Aggr: 96000*O(1)
			#   Recommendations:
			#    DArray;DArray;DArray: 96000*O(1)
		\end{verbatim}
		
		\item Important side note about the recommender: different data structures use different
			ways to perform the same action (eg. \texttt{DArray.add} calls
			\texttt{DArray.contains}, while \texttt{DHashSet.add} does not). The profiler can only
			count each access type for the currently used data structures and give recommendations
			for this combination of calls. Thus, using another combination might not lead to the
			complexity the recommender computed. For the given example, the recommender will work
			based on calls for both \texttt{add} and \texttt{contains}, although \texttt{DHashSet}
			never calls \texttt{contains} within \texttt{add}. It might be necessary to run the
			recommender more than once to yield better results.
		\item It takes a nearly static amount of time to compute the recommendations,
			independent of the chosen data structures and the graph size. Having it active in a
			setup with a small graph predominates the optimization of data structures
	\end{itemize}
